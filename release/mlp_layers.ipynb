{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before you turn this project in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9cfe71dfae6c038c765448b792ac2426",
     "grade": false,
     "grade_id": "data_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Load Data\n",
    "\n",
    "The following code loads in the MNIST dataset and displays a few images and flattens the images and sets some autograder variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53ebeabcec0d8358bcddc343f63e2bee",
     "grade": false,
     "grade_id": "data_code",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "[X, y], _ = mnist.load_data()\n",
    "for x in X[:5]:\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    img = array_to_img(x)\n",
    "    display(img)\n",
    "\n",
    "X = X.reshape([60_000, 28*28]) / 255.\n",
    "Y = to_categorical(y)\n",
    "X, Y = X[:50], Y[:50]\n",
    "\n",
    "M, N = X.shape\n",
    "C = np.unique(y).shape[0]\n",
    "H = 16\n",
    "\n",
    "def passed(): print('âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "341d578656e001b360d23c62630c3924",
     "grade": false,
     "grade_id": "layers_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "- Implement `Dense`, `Sigmoid`, and `SoftmaxCE` layers as classes and stick them in a file `layers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1a91b517e29663f52841c07a4624f507",
     "grade": false,
     "grade_id": "layers_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1ad9f8e29d7066dbb22d7aacc958d816",
     "grade": false,
     "grade_id": "mlp_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "- Define a one-hidden layer perceptron class called `LayeredMLP` which uses Dense, Sigmoid, and SoftmaxCE layers as in the computational graph\n",
    "\n",
    "![](images/mlp_predict.svg)\n",
    "\n",
    "where\n",
    "\n",
    "- $\\mathbf{X} \\in \\mathbb{R}^{M \\times N}$\n",
    "- $\\mathbf{W}^{(1)} \\in \\mathbb{R}^{N \\times H}$ and $\\mathbf{b}^{(1)} \\in \\mathbb{R}^{H}$\n",
    "- $\\mathbf{Z} \\in \\mathbb{R}^{M \\times H}$\n",
    "- $\\mathbf{H} \\in \\mathbb{R}^{M \\times H}$\n",
    "- $\\mathbf{W}^{(2)} \\in \\mathbb{R}^{H \\times C}$ and $\\mathbf{b}^{(2)} \\in \\mathbb{R}^{C}$\n",
    "- $\\mathbf{S} \\in \\mathbb{R}^{M \\times C}$\n",
    "- $\\mathbf{Y} \\in \\mathbb{R}^{M \\times C}$\n",
    "- $\\mathbf{L} \\in \\mathbb{R}^{M}$ and $\\overline{\\ell} \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c21ec5e306a4fb8927058eb135e44030",
     "grade": false,
     "grade_id": "mlp_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10ffcfb7827eaa3b97abe2ec0de0a71b",
     "grade": false,
     "grade_id": "constructor_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Constructor Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6456fc2c088b29b2734146de940878a",
     "grade": true,
     "grade_id": "constructor_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from classifiers import LayeredMLP\n",
    "import layers\n",
    "\n",
    "mlp = LayeredMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "\n",
    "assert type(mlp.dense1) == layers.Dense\n",
    "assert hasattr(mlp.dense1, 'W')\n",
    "assert hasattr(mlp.dense1, 'b')\n",
    "assert type(mlp.sigmoid) == layers.Sigmoid\n",
    "assert type(mlp.dense2) == layers.Dense\n",
    "assert hasattr(mlp.dense2, 'W')\n",
    "assert hasattr(mlp.dense2, 'b')\n",
    "assert type(mlp.softmaxce) == layers.SoftmaxCE\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "66b654e20e83c25cbc448a69673cf198",
     "grade": false,
     "grade_id": "predict_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79ccc7b5bc7b4b2854e54468976bd4fd",
     "grade": true,
     "grade_id": "prediction_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from classifiers import LayeredMLP\n",
    "\n",
    "mlp = LayeredMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "\n",
    "S = mlp.predict(X)\n",
    "nb_train_ = len(X)\n",
    "assert S.shape == (M, C)\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2163f3af2dc3c7f00eab3beacec44034",
     "grade": false,
     "grade_id": "evaluation_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Evaluation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7fcf89e44691cc461e79eccb073d677e",
     "grade": true,
     "grade_id": "evaluation_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from classifiers import LayeredMLP\n",
    "\n",
    "mlp = LayeredMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "\n",
    "acc = mlp.evaluate(X, Y)\n",
    "assert type(acc) == np.float64\n",
    "assert 0 <= acc <= 1\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e834ebdb01780cdc281380d484305035",
     "grade": false,
     "grade_id": "gradients_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "- Implement a `LayeredMLPWithGDOptimizer` class which performs optimization via gradient descent and extends your `LayeredMLP` class\n",
    "\n",
    "# Requirement\n",
    "\n",
    "- You must use backpropagation to compute gradients. To demonstrate this I am requiring your `_get_gradients()` function needs to return the gradient of every intermediate value in the computational graph as in\n",
    "\n",
    "![](images/mlp_full.svg)\n",
    "\n",
    "including `dX` (not pictured). You don't have to return `dloss`. Check the tests below to clear up any confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "726c59a0d5c5696a1f9177b4b04f8367",
     "grade": false,
     "grade_id": "gradients_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10d75c5b84146ba3896047ce95c44908",
     "grade": false,
     "grade_id": "gradients_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Gradient Checking Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fef657d4e033be30a4739f2fb877bb4",
     "grade": true,
     "grade_id": "gradients_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from classifiers import LayeredMLP, LayeredMLPWithGDOptimizer\n",
    "\n",
    "mlp = LayeredMLPWithGDOptimizer(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "assert issubclass(LayeredMLPWithGDOptimizer, LayeredMLP)\n",
    "\n",
    "gradients = mlp._get_gradients(X, Y)\n",
    "for gradient in gradients:\n",
    "    assert type(gradient) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "50eb25f31f236027bd6ff4810a4f80b0",
     "grade": false,
     "grade_id": "gradient_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Gradient Checking Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5aca1f661354de17ee0baed52ea8c2a4",
     "grade": true,
     "grade_id": "gradient_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from classifiers import LayeredMLPWithGDOptimizer\n",
    "from checking import estimate_gradients\n",
    "\n",
    "mlp = LayeredMLPWithGDOptimizer(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "\n",
    "estimated_gradients = estimate_gradients(mlp, X, Y)\n",
    "dX, dW1, db1, dZ, dH, dW2, db2, dS = mlp._get_gradients(X, Y)\n",
    "analytical_gradients, params = [dW1, db1, dW2, db2], ['dW1', 'db1', 'dW2', 'db2']\n",
    "grad_pairs = zip(estimated_gradients, analytical_gradients, params)\n",
    "for i, (estimated_gradient, analytic_gradient, param) in enumerate(grad_pairs):\n",
    "    try:\n",
    "        assert np.allclose(estimated_gradient, analytic_gradient)\n",
    "    except:\n",
    "        norm = np.square(estimated_gradient - analytic_gradient).mean()\n",
    "        logging.warning(f'{param} check failed with a difference of {norm}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73e0cb7f4c79e43926263c3e53066d5a",
     "grade": false,
     "grade_id": "optimizer_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Gradient Descent Optimizer Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6007fda16d797614ace0436ecd0967fe",
     "grade": true,
     "grade_id": "optimizer_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from classifiers import LayeredMLPWithGDOptimizer\n",
    "\n",
    "mlp = LayeredMLPWithGDOptimizer(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "\n",
    "X_sample, Y_sample = X[:50], Y[:50]\n",
    "acc = mlp.evaluate(X_sample, Y_sample)\n",
    "loss = mlp.forward(X_sample, Y_sample)\n",
    "for _ in range(10):\n",
    "    mlp.fit(X_sample, Y_sample, nb_epoch=10)\n",
    "    assert mlp.forward(X_sample, Y_sample) < loss\n",
    "    loss = mlp.forward(X_sample, Y_sample)\n",
    "    \n",
    "assert mlp.evaluate(X_sample, Y_sample) > acc\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a2daeba672f2bbee33bfe3796ad3fd0",
     "grade": false,
     "grade_id": "ignore",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Ignore Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7d8afec2c4454c9be1c1455cb533af35",
     "grade": false,
     "grade_id": "ignore_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
