{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this project in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Paul Tluczek\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82fb1e9f8ecc379592bf172fec0e0d2c",
     "grade": false,
     "grade_id": "autograder_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Load Data\n",
    "\n",
    "The following code loads in the MNIST dataset and displays a few images and flattens the images and sets some autograder variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3cc59bcad91024097ff4573b4afeebcd",
     "grade": false,
     "grade_id": "autograder_code",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE6D6C9A828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv\n/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL\n85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C\n8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo\n3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7p\nVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE6D41929E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMT\nAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjw\nFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/\n8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEV\nj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE6D4192DA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+\n/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65\ngA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fg\nCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE6D4192DD8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nN3QPwtBYRQG8EMU0e0u\nZLIw+QKXRZlMGC0GX8CglE0pk0VxPwQmE5YrJYPVIjYMlImSwXNiMOi97319AM/6O6fzh+g/Y5hr\n5mrRNByseAZba4D7EnlSN8wy3uAYXJOwDEw0ohKwD9mtxehqRLQBCnZr8GPkJ/Ll79y0m37GiIji\nK2AQsGMYiIbryyvjmZO20U9gAIcjTg43GhfethOROToO+En6xRUlZhnSjd+I6BY7xVIRY79w4Xap\nR9IOSTWWYSWUqE0xlH771R7UrULefm5U2pxVCt0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE6D4192CF8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "%load_ext autoreload\n",
    "\n",
    "[X_mnist, y_mnist], _ = mnist.load_data()\n",
    "for x in X_mnist[:5]:\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    img = array_to_img(x)\n",
    "    display(img)\n",
    "\n",
    "X_mnist = X_mnist.reshape([60_000, 28*28]) / 255.\n",
    "Y_mnist = to_categorical(y_mnist)\n",
    "X_mnist, Y_mnist = X_mnist[:50], Y_mnist[:50]\n",
    "\n",
    "M, N = X_mnist.shape\n",
    "C = np.unique(y_mnist).shape[0]\n",
    "H = 16\n",
    "\n",
    "def passed(): print('✅')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d47df5774edb0a79de47845c3c891274",
     "grade": false,
     "grade_id": "mlp_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "- Define a one-hidden layer perceptron class called `TFMLP` with TensorFlow as in the computational graph\n",
    "\n",
    "![](images/mlp_predict.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c21ec5e306a4fb8927058eb135e44030",
     "grade": false,
     "grade_id": "mlp_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to classifiers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a classifiers.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class TFMLP():    \n",
    "    def __init__(self, nb_feature, nb_hidden, nb_class):\n",
    "        self.X = tf.placeholder(tf.float32, [None, nb_feature], name = 'X')\n",
    "        self.Y = tf.placeholder(tf.float32, [None, nb_class], name = 'Y')\n",
    "        self.W1 = tf.Variable(initial_value=np.random.randn(nb_feature, nb_hidden), dtype=tf.float32, name = 'W1')\n",
    "        self.b1 = tf.Variable(initial_value=np.random.randn(nb_hidden), dtype=tf.float32, name = 'b1')        \n",
    "        self.W2 = tf.Variable(initial_value=np.random.randn(nb_hidden, nb_class), dtype=tf.float32, name = 'W2')\n",
    "        self.b2 = tf.Variable(initial_value=np.random.randn(nb_class), dtype=tf.float32, name = 'b2')\n",
    "        \n",
    "        self._f()\n",
    "        \n",
    "    def _f(self):\n",
    "        Z = tf.add(tf.matmul(self.X, self.W1), self.b1)\n",
    "        H = tf.div(tf.constant(1.0),\n",
    "                    tf.add(tf.constant(1.0), tf.exp(tf.negative(Z))))\n",
    "        S = tf.add(tf.matmul(H, self.W2), self.b2)  \n",
    "        self.P = tf.nn.softmax(S)        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.Y,axis=1), tf.argmax(self.P,axis=1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "        self.loss = tf.reduce_mean(-tf.reduce_sum(self.Y * tf.log(self.P), reduction_indices=[1]))        \n",
    "       \n",
    "    def predict(self, X):       \n",
    "        return self.P.eval(feed_dict={self.X:X})\n",
    "\n",
    "    def evaluate(self, X, Y):  \n",
    "        self.P.eval(feed_dict={self.X:X})\n",
    "        return self.accuracy.eval(feed_dict={self.X:X, self.Y:Y})\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        return self.loss.eval(feed_dict={self.X:X, self.Y:Y})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f78ba5b14e337b010285b4b1a7ed99a0",
     "grade": false,
     "grade_id": "input_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Input Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b88e8521255441adf16ca77fe95a806d",
     "grade": true,
     "grade_id": "input_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from classifiers import TFMLP\n",
    "\n",
    "mlp = TFMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "assert mlp.X.op.type == 'Placeholder'\n",
    "assert mlp.Y.op.type == 'Placeholder'\n",
    "mlp.X.get_shape().as_list() == [None, 784]\n",
    "mlp.Y.get_shape().as_list() == [None, 10]\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "08dfa803eccfeaaedc2e3972fca7ba60",
     "grade": false,
     "grade_id": "variable_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Variable Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7a22ad7cf3c9b06a71b46653d9f1865",
     "grade": true,
     "grade_id": "variable_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from classifiers import TFMLP\n",
    "\n",
    "mlp = TFMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "assert mlp.W1.op.type == 'VariableV2'\n",
    "assert mlp.b1.op.type == 'VariableV2'\n",
    "assert mlp.W1.get_shape().as_list() == [784, 16]\n",
    "assert mlp.b1.get_shape().as_list() == [16]\n",
    "assert mlp.W2.op.type == 'VariableV2'\n",
    "assert mlp.b2.op.type == 'VariableV2'\n",
    "assert mlp.W2.get_shape().as_list() == [16, 10]\n",
    "assert mlp.b2.get_shape().as_list() == [10]\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a73848f8bfb28042ab7b19b5d1758072",
     "grade": false,
     "grade_id": "output_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Output Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52c482e88b2ebc8c4704d4351a1d1fc9",
     "grade": true,
     "grade_id": "output_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from classifiers import TFMLP\n",
    "\n",
    "mlp = TFMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "assert mlp.loss.get_shape().as_list() == []\n",
    "assert mlp.P.get_shape().as_list() == [None, 10]\n",
    "assert mlp.accuracy.get_shape().as_list() == []\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "033df42e28e8d656dad686a75c3a9b19",
     "grade": false,
     "grade_id": "prediction_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ecce61d8a2e47bdee55c5be36a5c297d",
     "grade": true,
     "grade_id": "prediction_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from classifiers import TFMLP\n",
    "\n",
    "mlp = TFMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "S = mlp.predict(X_mnist)\n",
    "nb_train_ = len(X_mnist)\n",
    "assert S.shape == (M, C)\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82ce71c1bdde881f47489fea5e5edb16",
     "grade": false,
     "grade_id": "evaluation_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Evaluation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "05040962622d0556601e3d95f881654c",
     "grade": true,
     "grade_id": "evaluation_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from classifiers import TFMLP\n",
    "\n",
    "mlp = TFMLP(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "acc = mlp.evaluate(X_mnist, Y_mnist)\n",
    "assert type(acc) == tf.float32\n",
    "assert 0 <= acc <= 1\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f547c7bc0440f4556aefb14d71230aa6",
     "grade": false,
     "grade_id": "optimizer_description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task\n",
    "\n",
    "- Implement a `TFMLPWithGDOptimizer` class which performs optimization via gradient descent and extends your `TFMLP` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f9de2ee3d1e62d4345f5f7b9b259aa99",
     "grade": false,
     "grade_id": "optimizer_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to classifiers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a classifiers.py\n",
    "\n",
    "class TFMLPWithGDOptimizer(TFMLP):    \n",
    "    def __init__(self, nb_feature, nb_hidden, nb_class):\n",
    "        TFMLP.__init__(self, nb_feature, nb_hidden, nb_class)\n",
    "       \n",
    "    def fit(self, X, Y, sess, nb_epoch=10, learningrate=0.5):\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate=learningrate).minimize(self.loss)\n",
    "        for _ in range(nb_epoch):          \n",
    "            sess.run(fetches=[train_step, self.loss, self.accuracy], feed_dict={self.X: X, self.Y: Y})    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2779f333e4a4af1b2ac0bb16c9baede4",
     "grade": false,
     "grade_id": "optimizer_blurb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Gradient Descent Optimizer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6de55d3985961ea8602b31628e94f898",
     "grade": true,
     "grade_id": "optimizer_tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from classifiers import TFMLPWithGDOptimizer, TFMLP\n",
    "\n",
    "assert issubclass(TFMLPWithGDOptimizer, TFMLP)\n",
    "mlp = TFMLPWithGDOptimizer(nb_feature=N, nb_hidden=H, nb_class=C)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # initialize tensorflow variables\n",
    "\n",
    "X_sample, Y_sample = X_mnist[:50], Y_mnist[:50]\n",
    "acc = mlp.evaluate(X_sample, Y_sample)\n",
    "loss = mlp.forward(X_sample, Y_sample)\n",
    "for _ in range(10):\n",
    "    mlp.fit(X_sample, Y_sample, sess, nb_epoch=10)\n",
    "    assert mlp.forward(X_sample, Y_sample) < loss\n",
    "    loss = mlp.forward(X_sample, Y_sample)\n",
    "    \n",
    "assert mlp.evaluate(X_sample, Y_sample) > acc\n",
    "\n",
    "passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a2daeba672f2bbee33bfe3796ad3fd0",
     "grade": false,
     "grade_id": "ignore",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Ignore Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7d8afec2c4454c9be1c1455cb533af35",
     "grade": false,
     "grade_id": "ignore_solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
